{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7-XqmqETfVu"
      },
      "source": [
        " **Build a model using transfer learning to classify a image is cat or dog.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCu8a7ztHzRV",
        "outputId": "5135c9cc-e1d1-47da-d628-deb46ebedd1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # for mounting the drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGrKlfonTThx"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FN3-BvBYTtCz"
      },
      "outputs": [],
      "source": [
        "with ZipFile('/content/drive/MyDrive/dogs-vs-cats.zip','r') as zipObj:\n",
        "  # Extract all the content of zip file in current directory\n",
        "  zipObj.extractall()\n",
        "\n",
        "with ZipFile('train.zip','r') as zipObj:\n",
        "  # Extract all the content of zip file in current directory\n",
        "  zipObj.extractall()\n",
        "\n",
        "with ZipFile('test1.zip','r') as zipObj:\n",
        "  zipObj.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Sn9haPkPKe8"
      },
      "outputs": [],
      "source": [
        "# Create Directories\n",
        "from os import makedirs\n",
        "dataset_home='dataset_dogs_vs_cats/'\n",
        "subdirs=['train/','test/']\n",
        "for subdir in subdirs:\n",
        "  # create label subdirectories\n",
        "  labeldirs=['dogs/','cats/']\n",
        "  for labldir in labeldirs:\n",
        "    newdir=dataset_home+subdir+labldir\n",
        "    makedirs(newdir,exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QEciF-cSp0D"
      },
      "source": [
        "Now change your dataset to fit the format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkF5BSjfRmrL"
      },
      "outputs": [],
      "source": [
        "from os import listdir\n",
        "from shutil import copyfile\n",
        "# create directories\n",
        "from random import seed,random\n",
        "seed(1)\n",
        "# define ratio of pictures to use for validation\n",
        "val_ratio=0.25 # means 0.25% images will be used for validation\n",
        "# copy training dataset images into subdirectories\n",
        "src_directory='train' # src is source\n",
        "dataset_home='dataset_dogs_vs_cats/'\n",
        "for file in listdir(src_directory):\n",
        "  src=src_directory + '/' + file\n",
        "  dst_dir='train/' # destination directory\n",
        "  if random()<val_ratio:\n",
        "    dst_dir='test/'\n",
        "  if file .startswith('cat'):\n",
        "    dst=dataset_home+dst_dir+'cats/'+file\n",
        "    copyfile(src,dst)\n",
        "  elif file.startswith('dog'):\n",
        "    dst=dataset_home+dst_dir+'dogs/'+file\n",
        "    copyfile(src,dst) # copyfile is using to copy file from one place to another"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpGHhULi4Az"
      },
      "source": [
        "Prepare a model for the transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVrdvU1Ni8hc",
        "outputId": "d2b6a00e-30f6-4089-eeb9-8cf45363b401"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "model=VGG16(include_top=False,input_shape=(224,224,3)) # this is the input shape of VGG16\n",
        "# mark loaded layers as not trainable\n",
        "for layer in model.layers:\n",
        "  layer.trainable=False # means these layers are non trainable\n",
        "# add new classifier layers\n",
        "flat1=Flatten()(model.layers[-1].output) # now flatten out the final layers\n",
        "class1=Dense(128,activation='relu',kernel_initializer='he_uniform')(flat1) # adding one dense layer\n",
        "output=Dense(1,activation='sigmoid')(class1)\n",
        "# define new model\n",
        "model=Model(inputs=model.inputs,outputs=output) # now making a whole model\n",
        "# compile model\n",
        "opt=SGD(learning_rate=0.001,momentum=0.9) # define your optimizer,momentum gives us better conversion in gradient descent or optimizier , SGD is shocastic gradient descent\n",
        "model.compile(optimizer=opt,loss='binary_crossentropy',metrics=['accuracy']) # compile the model, since this is binary class classification that's why we use this in loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D4pqAVLs2Fg"
      },
      "source": [
        "Run the model using Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BhhGqmfs5rV",
        "outputId": "37b0edf3-fd9c-48d0-d32c-402ee27a29fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 18697 images belonging to 2 classes.\n",
            "Found 6303 images belonging to 2 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-33f4369dcea2>:10: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history=model.fit_generator(train_it,steps_per_epoch=len(train_it),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            " 86/293 [=======>......................] - ETA: 2:23:22 - loss: 0.5140 - accuracy: 0.9529"
          ]
        }
      ],
      "source": [
        "datagen=ImageDataGenerator(featurewise_center=True) # Generator helps loading images into the ram in batches.\n",
        "# specify imagenet mean values for centering\n",
        "datagen.mean=[123.68,116.79,103.939] # it helps that your data remains centralized\n",
        "# prepare iterator\n",
        "train_it=datagen.flow_from_directory('dataset_dogs_vs_cats/train/', # flow_from_directory helps its takes all the images from your directory in batches and then it creates a generator or iterator, train_it is training iterator\n",
        "  class_mode='binary',batch_size=64,target_size=(224,224))\n",
        "test_it=datagen.flow_from_directory('dataset_dogs_vs_cats/test/', # test_it is testing iterator\n",
        "  class_mode='binary',batch_size=64,target_size=(224,224))\n",
        "# fit model\n",
        "history=model.fit_generator(train_it,steps_per_epoch=len(train_it),\n",
        "  validation_data=test_it,validation_steps=len(test_it),epochs=5,verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IybxX2QR8lr"
      },
      "source": [
        "Plot the loss and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HM1kN_kWSAK9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "pyplot.subplot(211)\n",
        "pyplot.title('Cross Entropy Loss')\n",
        "pyplot.plot(history.history['loss'],color='blue',label='train')\n",
        "pyplot.plot(history.history['val_loss'],color='orange',label='test')\n",
        "# plot accuracy\n",
        "pyplot.subplot(212)\n",
        "pyplot.title('Classification Accuracy')\n",
        "pyplot.plot(history.history['accuracy'],color='blue',label='train')\n",
        "pyplot.plot(history.history['val_accuracy'],color='orange',label='test')\n",
        "# save file to plot\n",
        "filename=sys.argv[0].split('/')[-1]\n",
        "pyplot.savefig(filename+'_plot.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2RsW_WPT93D"
      },
      "source": [
        "Save the model for future use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7P2Vo_lSUC7j"
      },
      "outputs": [],
      "source": [
        "model.save('final_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgKMSol0Uh9w"
      },
      "source": [
        "Predict outputs from model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqbhRiP-UmD_"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import load_model\n",
        "# load and prepare the image\n",
        "# load the image\n",
        "model=load_model('final_model.h5')\n",
        "img=load_img('',target_size=(224,224))\n",
        "# convert to array\n",
        "img=img_to_array(img)\n",
        "# reshape into a single sample with 3 channels\n",
        "img=img.reshape(1,224,224,3)\n",
        "# center pixel data\n",
        "img=img.astype('float32')\n",
        "img=img-[123.68,116.79,103.939]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPfMHiYDWHR3"
      },
      "outputs": [],
      "source": [
        "# 1 is for dogs and 0 is for cats\n",
        "result=model.predict(img)\n",
        "print(result[0])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}